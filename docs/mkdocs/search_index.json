{
    "docs": [
        {
            "location": "/", 
            "text": "Autonym\n\n\nAutonym is another framework built on top of Express to simplify building REST APIs for your resources. However, its\nphilosophy sets it apart from most other Node.js API frameworks.\n\n\nIt is extremely lightweight and written in ES6. By design, it eliminates the need to scaffold controllers in your API,\nbecause they can be inferred automatically from your models. Models are just static classes with a few methods and in\nmany cases can just forward their arguments to an ORM. As a result, APIs built in Autonym require little coding but\nstill offer total control over each CRUD action for a resource, and are very easy to understand at a glance.\n\n\nPhilosophy\n\n\n\n\n\n\nIt's just middleware.\n Most frameworks take over your entire application, making it difficult to adjust an\n  existing app to the new framework's setup. This also results in endless frustration when trying to do something the\n  framework isn't designed to do. Autonym is just mounted like any other middleware, so you can add other middleware\n  and handlers before or after Autonym to do whatever you want, the way you normally would.\n\n\n\n\n\n\nNo bloat.\n Autonym follows the single responsibility principle and seeks to do just one thing well: map requests\n  to CRUD actions. Following from the previous principle, if your server needs to serve static assets as well, just\n  mount middleware beside Autonym for your other routes. If you authenticate with JWTs, mount your JWT middleware\n  before Autonym.\n\n\n\n\n\n\nYour API, your response.\n Autonym makes a habit of never sending the response to the user directly. This allows\n  you to intercept the response to make any adjustments. If you want to let Autonym handle the response, it exposes\n  another middleware to mount after that will send the response.\n\n\n\n\n\n\nData validation is standardized.\n Autonym validates JSON documents using the JSON schema spec. Since JSON\n  schemas are JSON documents themselves, they can be exposed to API clients who can do pre-emptive validation on their\n  end. For more comprehensive validation beyond JSON schemas, Autonym allows you to define validation and sanitization\n  \npolicies\n and map them to CRUD actions.\n\n\n\n\n\n\nFor better or for worse, database schemas are not document schemas.\n In real life, there is rarely a perfect 1:1\n  relationship between properties on the request body and column names in a table. Autonym doesn't attempt to unify\n  data models -- in fact, it doesn't care about databases at all! However, data store implementations are free to\n  define mapping functions to translate documents to queries.\n\n\n\n\n\n\nIt has no opinion about ORMs.\n Many REST frameworks are tightly coupled to ORMs, but, like the previous point,\n  we recognized that sometimes in the real world you fight ORMs more than you love them. Autonym lets you integrate\n  them to whatever extent you want. Autonym just expects a model to implement five CRUD methods. Whether those methods\n  forward the data to an ORM or just run some queries or ops directly is up to you.\n\n\n\n\n\n\nIsolation for testability.\n Each component of an Autonym app is designed to be unit testable: JSON schemas can\n  be tested independently, policies are just simple JavaScript functions that can be imported directly, models are\n  simple, isolated classes that never deal with request or response objects.\n\n\n\n\n\n\nEmbrace ES6.\n Autonym app components are heavily class-based and Autonym and its sister projects are written\n  with Babel. You can always write components with ES5, but Autonym is designed for modern apps. As a downside, it\n  \ndoes\n require higher versions of Node.\n\n\n\n\n\n\nDrawbacks\n\n\nIt is important to point out some of the limitations of Autonym as well.\n\n\n\n\n\n\nAutonym has no intrinsic understanding of related resources. The API does not understand foreign references and\n  will only return resource ids. This means that establishing relationships between models must be handled at the\n  database layer or manually in the API layer. However, this eliminates some of the complexity with setting up and\n  consuming an API with intricate routing, unintentionally costly joins, and recursive embedding.\n\n\n\n\n\n\nAutonym requires all resources to have a primary key that is named \nid\n. Composite primary keys or primary keys named\n  something different are not currently supported.\n\n\n\n\n\n\nAPIs generated by Autonym return data in a basic format but as of yet don't adhere to any strict standards. On the\n  roadmap is potentially an extension for conforming to \nJSON:API\n.", 
            "title": "Intro"
        }, 
        {
            "location": "/#autonym", 
            "text": "Autonym is another framework built on top of Express to simplify building REST APIs for your resources. However, its\nphilosophy sets it apart from most other Node.js API frameworks.  It is extremely lightweight and written in ES6. By design, it eliminates the need to scaffold controllers in your API,\nbecause they can be inferred automatically from your models. Models are just static classes with a few methods and in\nmany cases can just forward their arguments to an ORM. As a result, APIs built in Autonym require little coding but\nstill offer total control over each CRUD action for a resource, and are very easy to understand at a glance.", 
            "title": "Autonym"
        }, 
        {
            "location": "/#philosophy", 
            "text": "It's just middleware.  Most frameworks take over your entire application, making it difficult to adjust an\n  existing app to the new framework's setup. This also results in endless frustration when trying to do something the\n  framework isn't designed to do. Autonym is just mounted like any other middleware, so you can add other middleware\n  and handlers before or after Autonym to do whatever you want, the way you normally would.    No bloat.  Autonym follows the single responsibility principle and seeks to do just one thing well: map requests\n  to CRUD actions. Following from the previous principle, if your server needs to serve static assets as well, just\n  mount middleware beside Autonym for your other routes. If you authenticate with JWTs, mount your JWT middleware\n  before Autonym.    Your API, your response.  Autonym makes a habit of never sending the response to the user directly. This allows\n  you to intercept the response to make any adjustments. If you want to let Autonym handle the response, it exposes\n  another middleware to mount after that will send the response.    Data validation is standardized.  Autonym validates JSON documents using the JSON schema spec. Since JSON\n  schemas are JSON documents themselves, they can be exposed to API clients who can do pre-emptive validation on their\n  end. For more comprehensive validation beyond JSON schemas, Autonym allows you to define validation and sanitization\n   policies  and map them to CRUD actions.    For better or for worse, database schemas are not document schemas.  In real life, there is rarely a perfect 1:1\n  relationship between properties on the request body and column names in a table. Autonym doesn't attempt to unify\n  data models -- in fact, it doesn't care about databases at all! However, data store implementations are free to\n  define mapping functions to translate documents to queries.    It has no opinion about ORMs.  Many REST frameworks are tightly coupled to ORMs, but, like the previous point,\n  we recognized that sometimes in the real world you fight ORMs more than you love them. Autonym lets you integrate\n  them to whatever extent you want. Autonym just expects a model to implement five CRUD methods. Whether those methods\n  forward the data to an ORM or just run some queries or ops directly is up to you.    Isolation for testability.  Each component of an Autonym app is designed to be unit testable: JSON schemas can\n  be tested independently, policies are just simple JavaScript functions that can be imported directly, models are\n  simple, isolated classes that never deal with request or response objects.    Embrace ES6.  Autonym app components are heavily class-based and Autonym and its sister projects are written\n  with Babel. You can always write components with ES5, but Autonym is designed for modern apps. As a downside, it\n   does  require higher versions of Node.", 
            "title": "Philosophy"
        }, 
        {
            "location": "/#drawbacks", 
            "text": "It is important to point out some of the limitations of Autonym as well.    Autonym has no intrinsic understanding of related resources. The API does not understand foreign references and\n  will only return resource ids. This means that establishing relationships between models must be handled at the\n  database layer or manually in the API layer. However, this eliminates some of the complexity with setting up and\n  consuming an API with intricate routing, unintentionally costly joins, and recursive embedding.    Autonym requires all resources to have a primary key that is named  id . Composite primary keys or primary keys named\n  something different are not currently supported.    APIs generated by Autonym return data in a basic format but as of yet don't adhere to any strict standards. On the\n  roadmap is potentially an extension for conforming to  JSON:API .", 
            "title": "Drawbacks"
        }, 
        {
            "location": "/getting-started/", 
            "text": "Getting Started\n\n\nThe quickest way to get started is by using the \nYeoman generator\n,\nwhich scaffolds the structure of an Autonym app for you. However, this guide will take you through building an API from\nscratch, so we can walk through line by line how it works.\n\n\nPrerequisites\n\n\nIn these examples, we'll touch on each feature of Autonym by building an API for managing Person objects that are stored\nin a Postgres database. Needless to say, you'll want to have a recent version of Node/NPM installed as well as Postgres.\n\n\nIn addition, all examples of Autonym use features of ES6 that will require running with \nBabel\n.\nThis tutorial does include what is needed to get a Babel application running, but we don't cover ES6 features here. We\nrecommend checking out \nthe ES6 features list by lukehoban\n as a guide for any unfamiliar\nsyntax. You should also be comfortable with Express and understand concepts like middleware, request/response handling,\nand callbacks. Last, Autonym uses JSON schems. A complete example is included in this walkthrough, but you'll want to\nget comfortable writing your own schemas when you build a production API. We recommend the\n\nthorough documentation\n provided by the Space Telescope\nScience Institute.\n\n\nInstallation\n\n\nLet's start with a totally blank application. Create a new directory, change into it, and \nnpm init\n and follow the\nwizard to create a new \npackage.json\n in your project.\n\n\nNext, we'll install some dependencies to transpile the Babel source into ES5 at runtime. We'll also install\n\nnodemon\n, which is just a convenient tool that watches your source code for changes and\nautomatically restarts the API server.\n\n\nmkdir new-api \n cd $_\nnpm init\nnpm install --save-dev babel-cli babel-preset-node5 babel-preset-stage-2 nodemon\n\n\n\n\nTo run this app, you can use the \nnodemon\n executable instead of just \nnode\n. However, we want to override the command\nthat nodemon executes when the watched files change -- instead of running the \nnode\n executable, it needs to run\n\nbabel-node\n to transpile our ES6.\n\n\nLet's open up \npackage.json\n. Under the \nscripts\n section, we can add a \nstart\n script that will serve as an aliased\nshortcut to our command.\n\n\nscripts\n: {\n  \nstart\n: \nnodemon ./lib/app.js --exec babel-node\n\n}\n\n\n\n\nThe last thing we need to do is create a file called \n.babelrc\n in our project directory and populate it with:\n\n\n{\n  \npresets\n: [\nnode5\n, \nstage-2\n]\n}\n\n\n\n\nThis is enough to get a Babel app running; now let's install our normal dependencies. Autonym is just Express\nmiddleware, so we will need to install Express and its JSON-parsing companion body-parser. We'll install Autonym and the\nPostgres extension to make building models that connect to Postgres easier. Finally, we'll need some utility packages\nfor error handling; we'll cover what the last two dependencies are used for later in this guide.\n\n\nnpm install --save express body-parser autonym autonym-postgres-store autonym-client-errors instance-of-name\n\n\n\n\nCoding\n\n\nLet's organize our app by placing source code in a \nlib\n directory, and we'll create the entry point to our app as\n\napp.js\n like we specified in the \nnpm start\n script.\n\n\nA simple Express app\n\n\nIn \nlib/app.js\n we'll start by just creating a typical Express server.\n\n\n// lib/app.js\n\nimport express from 'express';\nimport bodyParser from 'body-parser';\nimport http from 'http';\n\nconst app = express();\napp.use(bodyParser.json({}));\n\napp.get('/', (req, res) =\n res.json({message: 'Hello world!'}));\n\nhttp.createServer(app).listen(3000, err =\n {\n  if (err) { throw err; }\n  console.log('Listening on port 3000');\n});\n\n\n\n\nThis is a bare-bones Express application. If you run this app with \nnpm start\n and everything goes well, you'll see a\n\nListening on port 3000\n in your stdout. Visiting \nhttp://localhost:3000/\n in your browser or favorite REST client\n(we're fans of \nPostman\n) should yield the JSON \n{\"message\":\"Hello world!\"}\n.\n\n\nRefactoring our Express app\n\n\nLet's make a few improvements before we continue: we'll replace the literal \n3000\n with an environment variable so it\ncan be controlled by the service running our app. We'll replace \nthrow err;\n with a reusable \nhandleError\n function for\nour application. And we'll register a listener for the \nunhandledRejection\n event, which will fire if any promises throw\nexceptions that aren't caught elsewhere in the application (just in case -- Node swallows up unhandled promise\nrejections, unlike synchronous exceptions, which will crash the application).\n\n\n// lib/app.js\n\nimport express from 'express';\nimport bodyParser from 'body-parser';\nimport http from 'http';\nimport handleError from './handle-error';\n\nprocess.on('unhandledRejection', handleError);\n\nconst app = express();\napp.use(bodyParser.json({}));\n\napp.get('/', (req, res) =\n res.json({message: 'Hello world!'}));\n\nhttp.createServer(app).listen(process.env.PORT, err =\n {\n  if (err) { return handleError(err); }\n  console.log(`Listening on port ${process.env.PORT}`);\n});\n\n\n\n\nNow, of course, \nPORT\n is an environment variable, so we should export it or save it to our shell profile.\n\n\nexport PORT=3000\n\n\n\n\nAnd we'll need to create our error handler as well, so create a new \nhandle-error.js\n.\n\n\nThis will just be a small file exporting a reusable function. This function will be called when errors occur and can\nchoose to log them out, send alerts to your on-call team, or crash the application.\n\n\nFor now, we're just going to throw the error, which will crash the app.\n\n\n// lib/handle-error.js\n\nfunction handleError (err) {\n  setImmediate(() =\n { throw err; });\n}\n\nexport default handleError;\n\n\n\n\nNote that we wrapped it in a \nsetImmediate\n call. This is because Express' default error when an exception is thrown\nduring a request is to catch it and pass it to a generic \"error middleware\", which simply logs the exception and carries\non. If an error makes it this far, we'd like to crash the app to reset its state. If we wrap the code in a\n\nsetImmediate\n call, it can't be caught by Express, since it will be thrown after Express finishes with the request.\n\n\nIntegrating Autonym\n\n\nAlright, let's actually start integrating Autonym into our Express application.\n\n\nBecause Autonym is just Express middleware, we can simply add an \napp.use()\n call with a new instance of Autonym.\n\n\n// lib/app.js\n\nimport express from 'express';\nimport bodyParser from 'body-parser';\nimport http from 'http';\nimport Autonym, {AutonymResponder} from 'autonym';\nimport handleError from './handle-error';\n\nprocess.on('unhandledRejection', handleError);\n\nconst app = express();\napp.use(bodyParser.json({}));\n\napp.get('/', (req, res) =\n res.json({message: 'Hello world!'}));\n\napp.use(new Autonym(__dirname).middleware);\napp.use(new AutonymResponder(handleError).middleware);\n\nhttp.createServer(app).listen(process.env.PORT, err =\n {\n  if (err) { return handleError(err); }\n  console.log(`Listening on port ${process.env.PORT}`);\n});\n\n\n\n\nA few things are going on here:\n\n\n\n\n\n\nWe created a new instance of the \nAutonym\n class, passing \n__dirname\n into the constructor. \n__dirname\n is a Node.js\n  constant that refers to the absolute path to the currently executing file (i.e. the path to \n./lib\n). Autonym will\n  attempt to import various \"components\" from this given directory by searching for files that match a pattern.\n\n\n\n\n\n\nWe mounted the \nautonym.middleware\n middleware onto the app. Now, all requests will pass through the instance of\n  Autonym at this stage in the middleware stack. Of course, since we mounted it after our \napp.get()\n middleware (which\n  does not call \nnext\n), our hello world example will not pass through Autonym. The best way to adapt existing\n  applications with Autonym is to add the Autonym middleware near the bottom of the stack, so as to not affect existing\n  APIs.\n\n\n\n\n\n\nWe also mounted \nnew AutonymResponder(handleError).middleware\n. The \nautonym.middleware\n will validate and process the\n  request, but the \nautonymResponder.middleware\n middleware will actually send it to the client. These are deliberately\n  kept separate so that you can tweak the response however you like in between these two handlers. Note that the\n  \nAutonymResponder\n constructor takes a \nhandleError\n function. In addition to passing the error to the client, this\n  function can be used to capture and handle errors that happened during the request/response life cycle.\n\n\n\n\n\n\nAutonym is now going to look for files in the directory we passed into the constructor, in this case the absolute path\nto \n./lib\n. Autonym will check for three subdirectories in the path provided to it: \nmodels\n, \npolicies\n, and \nschemas\n.\nGo ahead and create these three directories in the \nlib\n folder. Next, we'll describe and build each of these\ncomponents.\n\n\nOur first model\n\n\nLet's create a model that represents a person. Models are just classes that extend from the \nModel\n abstract class that\nis exported by Autonym.\n\n\n// lib/models/person.model.js\n\nimport {Model} from 'autonym';\n\nclass Person extends Model {\n}\n\nexport default Person;\n\n\n\n\nThis model doesn't do much yet! But, if we create some static methods with specific names, we can start to add\nfunctionality to our model. Let's start with the \n_find()\n method, which should return a list of people.\n\n\n// lib/models/person.model.js\n\nimport {Model} from 'autonym';\n\nclass Person extends Model {\n  static _find (query) {\n    return Promise.resolve([\n      {\n        id: '1',\n        firstName: 'John',\n        lastName: 'Galt',\n        employerId: '42'\n      }\n    ]);\n  }\n}\n\nexport default Person;\n\n\n\n\nBy defining this function, we've now added the ability for our API to \"get people.\" The abstract Model class noticed\nthat the \n_find()\n function was defined, so it will call it any time you make a GET request to \n/people\n. Your function\n\nmust\n return a promise and that promise \nmust\n pass back an array. For now, that array is just static data.\n\n\nThere are four other CRUD methods (\n_create()\n, \n_findOne()\n, \n_findOneAndUpdate()\n, \n_findOneAndDelete()\n) which are\ndescribed in more detail in the API reference. Note that if any of them aren't set on your model, it's okay -- your user\nwill just receive a method not allowed error. However, note that \n_findOne()\n \nmust\n be set up in order for\n\n_findOneAndUpdate()\n and \n_findOneAndDelete()\n to work.\n\n\nGo ahead! Hit \nhttp://localhost:3000/people\n in your browser or Postman and you should get back the array.\n\n\nBehind the scenes, Autonym processes a GET request, parses the incoming data, forwards the relevant parts of the request\nto \n_find()\n, then reformats the results and passes them onto the next middleware in the stack. In this case, the next\nmiddleware is the AutonymResponder, which just returns the response. However, if you wanted to, for example, wrap that\narray inside an object (e.g. \n{\"data\": []}\n) or add some specific headers, you could add more middleware in between --\nall Autonym does is add some properties to the \nreq\n and \nres\n objects from Express with additional information. More\ninformation about how this works and how to hook into this process is available in the API section.\n\n\nUsing the Postgres Store\n\n\nWe could define the additional methods like \n_create()\n and \n_findOne()\n, but that might seem tedious. If we had a\ncustom datastore, we might implement these methods manually. But since we're using Postgres, we can automate that work.\n\n\nFirst, let's create a Postgres database and add a new table to hold people. Let's create a Postgres database and a new\ntable.\n\n\ncreatedb autonym_app\npsql autonym_app\n\n CREATE TABLE people (\n  id BIGSERIAL PRIMARY KEY,\n  first_name VARCHAR(255) NOT NULL,\n  last_name VARCHAR(255) NOT NULL,\n  employer_id BIGINT NOT NULL\n);\n\n\n\n\nNote that the primary key has to be a column called \nid\n for Autonym to work.\n\n\nWe also need to tell Autonym how to connect to our Postgres store. This is done with another environment variable, so\nyou let's export another environment variable.\n\n\nexport POSTGRES_CONNECTION=\npostgres://$USER@localhost:5432/autonym_app\n\n\n\n\n\nNow we can leverage the Postgres store extension in our model.\n\n\n// lib/models/person.model.js\n\nimport {Model} from 'autonym';\nimport PostgresStoreFactory from 'autonym-postgres-store';\n\nconst PostgresStore = PostgresStoreFactory();\n\nclass Person extends Model {\n  static _init () {\n    this.store = new PostgresStore('people');\n    super._implementDefaultStoreCrudMethods(this.store);\n  }\n}\n\nexport default Person;\n\n\n\n\nHere, we've attached a static \n_init()\n method. It creates a new property on the class called \nstore\n and instantiates a\n\nPostgresStore\n, passing in the name of our table. Then, we call \n_implementDefaultStoreCrudMethods()\n, which is a\nfunction on the abstract Model class, providing our store instance. All this fancy function does is copy the \ncreate()\n,\n\nfind()\n, \nfindOne()\n, \nfindOneAndUpdate()\n, \nfindOneAndDelete()\n, \nserialize()\n, and \nunserialize()\n functions from the\nstore to our model class. This is basically just a quicker way of doing something like:\n\n\nstatic _create () { return this.store.create(...arguments); }\nstatic _find () { return this.store.find(...arguments); }\nstatic _findOne () { return this.store.findOne(...arguments); }\n// ...\n\n\n\n\nAt this point, we've essentially defined our Person model, and it's fully integrated with Postgres. Using a REST client,\ntry some requests:\n\n\n\n\nPOST http://localhost:3000/people\n\n\n\n\nRequest\n\n\n{\nfirstName\n:\nJohn\n,\nlastName\n:\nGalt\n,\nemployerId\n:\n42\n}\n\n\n\n\nResponse\n\n\n{\nid\n:1,\nfirstName\n:\nJohn\n,\nlastName\n:\nGalt\n,\nemployerId\n:\n42\n}\n\n\n\n\n\n\nPOST http://localhost:3000/people\n\n\n\n\nRequest\n\n\n{\nfirstName\n:\nDagny\n,\nlastName\n:\nTaggart\n,\nemployerId\n:\n42\n}\n\n\n\n\nResponse\n\n\n{\nid\n:2,\nfirstName\n:\nDagny\n,\nlastName\n:\nTaggart\n,\nemployerId\n:\n42\n}\n\n\n\n\n\n\nGET http://localhost:3000/people\n\n\n\n\nResponse\n\n\n[{\nid\n:1,\nfirstName\n:\nJohn\n,\nlastName\n:\nGalt\n,\nemployerId\n:\n42\n},{\nid\n:2,\nfirstName\n:\nDagny\n,\nlastName\n:\nTaggart\n,\nemployerId\n:\n42\n}]\n\n\n\n\n\n\nGET http://localhost:3000/people/1\n\n\n\n\nResponse\n\n\n{\nid\n:1,\nfirstName\n:\nJohn\n,\nlastName\n:\nGalt\n,\nemployerId\n:\n42\n}\n\n\n\n\n\n\nPATCH http://localhost:3000/people/2\n\n\n\n\nRequest\n\n\n{\nlastName\n:\nGalt\n}\n\n\n\n\nResponse\n\n\n{\nid\n:2,\nfirstName\n:\nDagny\n,\nlastName\n:\nGalt\n,\nemployerId\n:\n42\n}\n\n\n\n\n\n\nGET http://localhost:3000/people?search[firstName][~]=dag\n\n\n\n\nResponse\n\n\n[{\nid\n:2,\nfirstName\n:\nDagny\n,\nlastName\n:\nGalt\n,\nemployerId\n:\n42\n}]\n\n\n\n\n\n\nGET http://localhost:3000/people?sort=+firstName\n\n\n\n\nResponse\n\n\n[{\nid\n:2,\nfirstName\n:\nDagny\n,\nlastName\n:\nGalt\n,\nemployerId\n:\n42\n},{\nid\n:1,\nfirstName\n:\nJohn\n,\nlastName\n:\nGalt\n,\nemployerId\n:\n42\n}]\n\n\n\n\n\n\nDELETE http://localhost:3000/people/1\n\n\n\n\nResponse\n\n\nno content\n\n\nAdding a JSON schema\n\n\nSo there we have a working model! However, you should probably see in your stdout a warning about missing a schema.\nWithout JSON schema validation, this is a huge security violation. Any data can be sent to our API and the Postgres\nstore will try to insert it, even if the columns don't exist, are of the wrong type, or worse -- are columns users\nshouldn't be allowed to write to (like \nid\n)!\n\n\nLet's create a JSON schema for our Person model. Properties that aren't defined in the schema will be automatically\ndiscarded from the request, and the defined properties will be properly validated.\n\n\n// lib/schemas/person.schema.json\n\n{\n  \nid\n: \nPerson\n,\n  \ntype\n: \nobject\n,\n  \nproperties\n: {\n    \nfirstName\n: {\ntype\n: \nstring\n, \nminLength\n: 1, \nmaxLength\n: 20},\n    \nlastName\n: {\ntype\n: \nstring\n, \nminLength\n: 1, \nmaxLength\n: 20},\n    \nemployerId\n: {\ntype\n: \nstring\n, \nminLength\n: 1, \nmaxLength\n: 10}\n  },\n  \nrequired\n: [\nfirstName\n, \nlastName\n, \nemployerId\n]\n}\n\n\n\n\nNow, JSON schema validation will be properly enforced against any operations to the model. The schema is automatically\nmatched to the model because its \nid\n is \nPerson\n, which is the same as the name of our model.\n\n\nIf you try sending an invalid request, you'll notice your app crashes. That's because the \nhandleError\n method is\ncrashing it when \nany\n error occurs. Let's make some adjustments.\n\n\n// lib/handle-error.js\n\nimport instanceOf from 'instance-of-name';\n\nfunction handleError (err) {\n  if ('internalQuery' in err) {\n    console.error(err);\n  } else if (instanceOf(err, 'ClientError')) {\n    console.log(err.message);\n  } else {\n    setImmediate(() =\n { throw err; });\n  }\n}\n\nexport default handleError;\n\n\n\n\nHere we'll walk through some changes we made:\n\n\n\n\nWe're \"duck-typing\" the error to see if it has an \ninternalQuery\n property. If that property exists, it probably means\n  the error originated from the Postgres database driver. This could mean something bad, but generally an erroneous\n  query doesn't mean the app has to crash, it might be due to a misconfigured model or a search query that just wouldn't\n  work. Let's log it out to stderr, but we'll keep the app going.\n\n\nThe next condition checks if the error was derived from a class called \nClientError\n. \nClientError\n is a special class\n  that Autonym uses for any errors that are the result of a bad request on behalf of the client. The app is totally fine,\n  but the user got back an error message. Here, we're printing it out just for verbosity, but we could safely ignore\n  these errors.\n\n\nOtherwise we'll continue with our default behavior and crash the app.\n\n\n\n\nCreating a policy\n\n\nThe last feature we'll explore in this guide is policies. Policies are a lot like Express middleware and are simply\nfunctions that perform sanitization and validation on requests that are beyond the capabilities of JSON schemas. Common\nfunctions of policies are:\n\n\n\n\nadd a timestamp to every resource\n\n\nadd hard-coded filters to searches to restrict result sets\n\n\nvalidate that the user has permission to perform the action\n\n\n\n\nWe're going to only allow people to make updates if they are editing themselves. Let's create a policy that checks some\nproperty on the request to see if it matches the resource being updated.\n\n\n// lib/policies/is-self.policy.js\n\nimport {ForbiddenError} from 'autonym-client-errors';\n\nfunction isSelf (req) {\n  if (req.query.userId !== req.resourceId) {\n    throw new ForbiddenError('You do not have permission to update this resource');\n  }\n}\n\nexport default isSelf;\n\n\n\n\nIn this contrived example, our way of telling if the current user is the user being updated, we're simply checking a\n\nuserId\n parameter in the query string. Horribly insecure, but easy to test. Note that we are throwing an instance of\n\nForbiddenError\n. It is important that your policy throw some subclass from the autonym-client-errors package, such as\n\nForbiddenError\n. If an internal error occurred (like a rejected database connection or a timeout), just throw it and\nAutonymResponder will return a 500 error and pass it onto your \nhandleError\n method; but if the error just indicates\nsomething the client did wrong, always make sure to throw a subclass of ClientError.\n\n\nIt doesn't matter what the function \nreturns\n, unless it is a promise. If it's a promise, then the promise can resolve\nwith anything, or reject and it will be treated just like the throw example.\n\n\nYou may also have noticed the \nreq.resourceId\n property, which is nonstandard on the \nreq\n object in Express. Autonym\naggregates the \nreq\n object with many properties, which are documented in the API reference.\n\n\nLet's attach this policy to the \nfindOneAndUpdate\n action, which we can do by modifying our schema.\n\n\n// lib/schemas/person.schema.json\n\n{\n  \nid\n: \nPerson\n,\n  \ntype\n: \nobject\n,\n  \npolicies\n: {\n    \nfindOneAndUpdate\n: \nisAdmin\n\n  },\n  \nproperties\n: {\n    \nfirstName\n: {\ntype\n: \nstring\n, \nminLength\n: 1, \nmaxLength\n: 20},\n    \nlastName\n: {\ntype\n: \nstring\n, \nminLength\n: 1, \nmaxLength\n: 20},\n    \nemployeeId\n: {\ntype\n: \nstring\n, \nminLength\n: 1, \nmaxLength\n: 10}\n  },\n  \nrequired\n: [\nfirstName\n, \nlastName\n, \nclientId\n]\n}\n\n\n\n\nNow if we reattempt a PATCH request on \n/people/42\n, we should get back a forbidden error. However, if try a request to\n\n/people/42?userId=42\n, we should get a success (assuming a person with id 42 exists). Obviously this is just a simple\nexample and not a valid means of authentication.\n\n\nThe \npolicies\n object on the schema can have \n*\n, \ncreate\n, \nfind\n, \nfindOne\n, \nfindOneAndUpdate\n, and\n\nfindOneAndDelete\n definitions. The \n*\n applies to \nall\n CRUD operations and is always evaluated first.\n\n\nThe values in the \npolicies\n object are actually \"asynchronous boolean expressions.\" At their simplest, they're just\nnames of policies. However, you can actually mix and match policies by using the syntax defined in\n\nasync-boolean-expression-evaluator\n. This allows you\nto combine policies, like \n{\"or\": [\"isAdmin\", \"isSelf\"]}\n or\n\n{\"and\": [\"isLoggedIn\", {\"or\": [\"isAdmin\", \"canChangePassword\"]}]}\n.\n\n\nAfterword\n\n\nHopefully this tutorial helped you get started with your first Autonym app! There's a lot more to it, and also a lot\nmore work for us to do. Please let us know what you think in the Issues section, and as always, pull requests are\nwelcome!", 
            "title": "Getting Started"
        }, 
        {
            "location": "/getting-started/#getting-started", 
            "text": "The quickest way to get started is by using the  Yeoman generator ,\nwhich scaffolds the structure of an Autonym app for you. However, this guide will take you through building an API from\nscratch, so we can walk through line by line how it works.", 
            "title": "Getting Started"
        }, 
        {
            "location": "/getting-started/#prerequisites", 
            "text": "In these examples, we'll touch on each feature of Autonym by building an API for managing Person objects that are stored\nin a Postgres database. Needless to say, you'll want to have a recent version of Node/NPM installed as well as Postgres.  In addition, all examples of Autonym use features of ES6 that will require running with  Babel .\nThis tutorial does include what is needed to get a Babel application running, but we don't cover ES6 features here. We\nrecommend checking out  the ES6 features list by lukehoban  as a guide for any unfamiliar\nsyntax. You should also be comfortable with Express and understand concepts like middleware, request/response handling,\nand callbacks. Last, Autonym uses JSON schems. A complete example is included in this walkthrough, but you'll want to\nget comfortable writing your own schemas when you build a production API. We recommend the thorough documentation  provided by the Space Telescope\nScience Institute.", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/getting-started/#installation", 
            "text": "Let's start with a totally blank application. Create a new directory, change into it, and  npm init  and follow the\nwizard to create a new  package.json  in your project.  Next, we'll install some dependencies to transpile the Babel source into ES5 at runtime. We'll also install nodemon , which is just a convenient tool that watches your source code for changes and\nautomatically restarts the API server.  mkdir new-api   cd $_\nnpm init\nnpm install --save-dev babel-cli babel-preset-node5 babel-preset-stage-2 nodemon  To run this app, you can use the  nodemon  executable instead of just  node . However, we want to override the command\nthat nodemon executes when the watched files change -- instead of running the  node  executable, it needs to run babel-node  to transpile our ES6.  Let's open up  package.json . Under the  scripts  section, we can add a  start  script that will serve as an aliased\nshortcut to our command.  scripts : {\n   start :  nodemon ./lib/app.js --exec babel-node \n}  The last thing we need to do is create a file called  .babelrc  in our project directory and populate it with:  {\n   presets : [ node5 ,  stage-2 ]\n}  This is enough to get a Babel app running; now let's install our normal dependencies. Autonym is just Express\nmiddleware, so we will need to install Express and its JSON-parsing companion body-parser. We'll install Autonym and the\nPostgres extension to make building models that connect to Postgres easier. Finally, we'll need some utility packages\nfor error handling; we'll cover what the last two dependencies are used for later in this guide.  npm install --save express body-parser autonym autonym-postgres-store autonym-client-errors instance-of-name", 
            "title": "Installation"
        }, 
        {
            "location": "/getting-started/#coding", 
            "text": "Let's organize our app by placing source code in a  lib  directory, and we'll create the entry point to our app as app.js  like we specified in the  npm start  script.", 
            "title": "Coding"
        }, 
        {
            "location": "/getting-started/#a-simple-express-app", 
            "text": "In  lib/app.js  we'll start by just creating a typical Express server.  // lib/app.js\n\nimport express from 'express';\nimport bodyParser from 'body-parser';\nimport http from 'http';\n\nconst app = express();\napp.use(bodyParser.json({}));\n\napp.get('/', (req, res) =  res.json({message: 'Hello world!'}));\n\nhttp.createServer(app).listen(3000, err =  {\n  if (err) { throw err; }\n  console.log('Listening on port 3000');\n});  This is a bare-bones Express application. If you run this app with  npm start  and everything goes well, you'll see a Listening on port 3000  in your stdout. Visiting  http://localhost:3000/  in your browser or favorite REST client\n(we're fans of  Postman ) should yield the JSON  {\"message\":\"Hello world!\"} .", 
            "title": "A simple Express app"
        }, 
        {
            "location": "/getting-started/#refactoring-our-express-app", 
            "text": "Let's make a few improvements before we continue: we'll replace the literal  3000  with an environment variable so it\ncan be controlled by the service running our app. We'll replace  throw err;  with a reusable  handleError  function for\nour application. And we'll register a listener for the  unhandledRejection  event, which will fire if any promises throw\nexceptions that aren't caught elsewhere in the application (just in case -- Node swallows up unhandled promise\nrejections, unlike synchronous exceptions, which will crash the application).  // lib/app.js\n\nimport express from 'express';\nimport bodyParser from 'body-parser';\nimport http from 'http';\nimport handleError from './handle-error';\n\nprocess.on('unhandledRejection', handleError);\n\nconst app = express();\napp.use(bodyParser.json({}));\n\napp.get('/', (req, res) =  res.json({message: 'Hello world!'}));\n\nhttp.createServer(app).listen(process.env.PORT, err =  {\n  if (err) { return handleError(err); }\n  console.log(`Listening on port ${process.env.PORT}`);\n});  Now, of course,  PORT  is an environment variable, so we should export it or save it to our shell profile.  export PORT=3000  And we'll need to create our error handler as well, so create a new  handle-error.js .  This will just be a small file exporting a reusable function. This function will be called when errors occur and can\nchoose to log them out, send alerts to your on-call team, or crash the application.  For now, we're just going to throw the error, which will crash the app.  // lib/handle-error.js\n\nfunction handleError (err) {\n  setImmediate(() =  { throw err; });\n}\n\nexport default handleError;  Note that we wrapped it in a  setImmediate  call. This is because Express' default error when an exception is thrown\nduring a request is to catch it and pass it to a generic \"error middleware\", which simply logs the exception and carries\non. If an error makes it this far, we'd like to crash the app to reset its state. If we wrap the code in a setImmediate  call, it can't be caught by Express, since it will be thrown after Express finishes with the request.", 
            "title": "Refactoring our Express app"
        }, 
        {
            "location": "/getting-started/#integrating-autonym", 
            "text": "Alright, let's actually start integrating Autonym into our Express application.  Because Autonym is just Express middleware, we can simply add an  app.use()  call with a new instance of Autonym.  // lib/app.js\n\nimport express from 'express';\nimport bodyParser from 'body-parser';\nimport http from 'http';\nimport Autonym, {AutonymResponder} from 'autonym';\nimport handleError from './handle-error';\n\nprocess.on('unhandledRejection', handleError);\n\nconst app = express();\napp.use(bodyParser.json({}));\n\napp.get('/', (req, res) =  res.json({message: 'Hello world!'}));\n\napp.use(new Autonym(__dirname).middleware);\napp.use(new AutonymResponder(handleError).middleware);\n\nhttp.createServer(app).listen(process.env.PORT, err =  {\n  if (err) { return handleError(err); }\n  console.log(`Listening on port ${process.env.PORT}`);\n});  A few things are going on here:    We created a new instance of the  Autonym  class, passing  __dirname  into the constructor.  __dirname  is a Node.js\n  constant that refers to the absolute path to the currently executing file (i.e. the path to  ./lib ). Autonym will\n  attempt to import various \"components\" from this given directory by searching for files that match a pattern.    We mounted the  autonym.middleware  middleware onto the app. Now, all requests will pass through the instance of\n  Autonym at this stage in the middleware stack. Of course, since we mounted it after our  app.get()  middleware (which\n  does not call  next ), our hello world example will not pass through Autonym. The best way to adapt existing\n  applications with Autonym is to add the Autonym middleware near the bottom of the stack, so as to not affect existing\n  APIs.    We also mounted  new AutonymResponder(handleError).middleware . The  autonym.middleware  will validate and process the\n  request, but the  autonymResponder.middleware  middleware will actually send it to the client. These are deliberately\n  kept separate so that you can tweak the response however you like in between these two handlers. Note that the\n   AutonymResponder  constructor takes a  handleError  function. In addition to passing the error to the client, this\n  function can be used to capture and handle errors that happened during the request/response life cycle.    Autonym is now going to look for files in the directory we passed into the constructor, in this case the absolute path\nto  ./lib . Autonym will check for three subdirectories in the path provided to it:  models ,  policies , and  schemas .\nGo ahead and create these three directories in the  lib  folder. Next, we'll describe and build each of these\ncomponents.", 
            "title": "Integrating Autonym"
        }, 
        {
            "location": "/getting-started/#our-first-model", 
            "text": "Let's create a model that represents a person. Models are just classes that extend from the  Model  abstract class that\nis exported by Autonym.  // lib/models/person.model.js\n\nimport {Model} from 'autonym';\n\nclass Person extends Model {\n}\n\nexport default Person;  This model doesn't do much yet! But, if we create some static methods with specific names, we can start to add\nfunctionality to our model. Let's start with the  _find()  method, which should return a list of people.  // lib/models/person.model.js\n\nimport {Model} from 'autonym';\n\nclass Person extends Model {\n  static _find (query) {\n    return Promise.resolve([\n      {\n        id: '1',\n        firstName: 'John',\n        lastName: 'Galt',\n        employerId: '42'\n      }\n    ]);\n  }\n}\n\nexport default Person;  By defining this function, we've now added the ability for our API to \"get people.\" The abstract Model class noticed\nthat the  _find()  function was defined, so it will call it any time you make a GET request to  /people . Your function must  return a promise and that promise  must  pass back an array. For now, that array is just static data.  There are four other CRUD methods ( _create() ,  _findOne() ,  _findOneAndUpdate() ,  _findOneAndDelete() ) which are\ndescribed in more detail in the API reference. Note that if any of them aren't set on your model, it's okay -- your user\nwill just receive a method not allowed error. However, note that  _findOne()   must  be set up in order for _findOneAndUpdate()  and  _findOneAndDelete()  to work.  Go ahead! Hit  http://localhost:3000/people  in your browser or Postman and you should get back the array.  Behind the scenes, Autonym processes a GET request, parses the incoming data, forwards the relevant parts of the request\nto  _find() , then reformats the results and passes them onto the next middleware in the stack. In this case, the next\nmiddleware is the AutonymResponder, which just returns the response. However, if you wanted to, for example, wrap that\narray inside an object (e.g.  {\"data\": []} ) or add some specific headers, you could add more middleware in between --\nall Autonym does is add some properties to the  req  and  res  objects from Express with additional information. More\ninformation about how this works and how to hook into this process is available in the API section.", 
            "title": "Our first model"
        }, 
        {
            "location": "/getting-started/#using-the-postgres-store", 
            "text": "We could define the additional methods like  _create()  and  _findOne() , but that might seem tedious. If we had a\ncustom datastore, we might implement these methods manually. But since we're using Postgres, we can automate that work.  First, let's create a Postgres database and add a new table to hold people. Let's create a Postgres database and a new\ntable.  createdb autonym_app\npsql autonym_app  CREATE TABLE people (\n  id BIGSERIAL PRIMARY KEY,\n  first_name VARCHAR(255) NOT NULL,\n  last_name VARCHAR(255) NOT NULL,\n  employer_id BIGINT NOT NULL\n);  Note that the primary key has to be a column called  id  for Autonym to work.  We also need to tell Autonym how to connect to our Postgres store. This is done with another environment variable, so\nyou let's export another environment variable.  export POSTGRES_CONNECTION= postgres://$USER@localhost:5432/autonym_app   Now we can leverage the Postgres store extension in our model.  // lib/models/person.model.js\n\nimport {Model} from 'autonym';\nimport PostgresStoreFactory from 'autonym-postgres-store';\n\nconst PostgresStore = PostgresStoreFactory();\n\nclass Person extends Model {\n  static _init () {\n    this.store = new PostgresStore('people');\n    super._implementDefaultStoreCrudMethods(this.store);\n  }\n}\n\nexport default Person;  Here, we've attached a static  _init()  method. It creates a new property on the class called  store  and instantiates a PostgresStore , passing in the name of our table. Then, we call  _implementDefaultStoreCrudMethods() , which is a\nfunction on the abstract Model class, providing our store instance. All this fancy function does is copy the  create() , find() ,  findOne() ,  findOneAndUpdate() ,  findOneAndDelete() ,  serialize() , and  unserialize()  functions from the\nstore to our model class. This is basically just a quicker way of doing something like:  static _create () { return this.store.create(...arguments); }\nstatic _find () { return this.store.find(...arguments); }\nstatic _findOne () { return this.store.findOne(...arguments); }\n// ...  At this point, we've essentially defined our Person model, and it's fully integrated with Postgres. Using a REST client,\ntry some requests:   POST http://localhost:3000/people   Request  { firstName : John , lastName : Galt , employerId : 42 }  Response  { id :1, firstName : John , lastName : Galt , employerId : 42 }   POST http://localhost:3000/people   Request  { firstName : Dagny , lastName : Taggart , employerId : 42 }  Response  { id :2, firstName : Dagny , lastName : Taggart , employerId : 42 }   GET http://localhost:3000/people   Response  [{ id :1, firstName : John , lastName : Galt , employerId : 42 },{ id :2, firstName : Dagny , lastName : Taggart , employerId : 42 }]   GET http://localhost:3000/people/1   Response  { id :1, firstName : John , lastName : Galt , employerId : 42 }   PATCH http://localhost:3000/people/2   Request  { lastName : Galt }  Response  { id :2, firstName : Dagny , lastName : Galt , employerId : 42 }   GET http://localhost:3000/people?search[firstName][~]=dag   Response  [{ id :2, firstName : Dagny , lastName : Galt , employerId : 42 }]   GET http://localhost:3000/people?sort=+firstName   Response  [{ id :2, firstName : Dagny , lastName : Galt , employerId : 42 },{ id :1, firstName : John , lastName : Galt , employerId : 42 }]   DELETE http://localhost:3000/people/1   Response  no content", 
            "title": "Using the Postgres Store"
        }, 
        {
            "location": "/getting-started/#adding-a-json-schema", 
            "text": "So there we have a working model! However, you should probably see in your stdout a warning about missing a schema.\nWithout JSON schema validation, this is a huge security violation. Any data can be sent to our API and the Postgres\nstore will try to insert it, even if the columns don't exist, are of the wrong type, or worse -- are columns users\nshouldn't be allowed to write to (like  id )!  Let's create a JSON schema for our Person model. Properties that aren't defined in the schema will be automatically\ndiscarded from the request, and the defined properties will be properly validated.  // lib/schemas/person.schema.json\n\n{\n   id :  Person ,\n   type :  object ,\n   properties : {\n     firstName : { type :  string ,  minLength : 1,  maxLength : 20},\n     lastName : { type :  string ,  minLength : 1,  maxLength : 20},\n     employerId : { type :  string ,  minLength : 1,  maxLength : 10}\n  },\n   required : [ firstName ,  lastName ,  employerId ]\n}  Now, JSON schema validation will be properly enforced against any operations to the model. The schema is automatically\nmatched to the model because its  id  is  Person , which is the same as the name of our model.  If you try sending an invalid request, you'll notice your app crashes. That's because the  handleError  method is\ncrashing it when  any  error occurs. Let's make some adjustments.  // lib/handle-error.js\n\nimport instanceOf from 'instance-of-name';\n\nfunction handleError (err) {\n  if ('internalQuery' in err) {\n    console.error(err);\n  } else if (instanceOf(err, 'ClientError')) {\n    console.log(err.message);\n  } else {\n    setImmediate(() =  { throw err; });\n  }\n}\n\nexport default handleError;  Here we'll walk through some changes we made:   We're \"duck-typing\" the error to see if it has an  internalQuery  property. If that property exists, it probably means\n  the error originated from the Postgres database driver. This could mean something bad, but generally an erroneous\n  query doesn't mean the app has to crash, it might be due to a misconfigured model or a search query that just wouldn't\n  work. Let's log it out to stderr, but we'll keep the app going.  The next condition checks if the error was derived from a class called  ClientError .  ClientError  is a special class\n  that Autonym uses for any errors that are the result of a bad request on behalf of the client. The app is totally fine,\n  but the user got back an error message. Here, we're printing it out just for verbosity, but we could safely ignore\n  these errors.  Otherwise we'll continue with our default behavior and crash the app.", 
            "title": "Adding a JSON schema"
        }, 
        {
            "location": "/getting-started/#creating-a-policy", 
            "text": "The last feature we'll explore in this guide is policies. Policies are a lot like Express middleware and are simply\nfunctions that perform sanitization and validation on requests that are beyond the capabilities of JSON schemas. Common\nfunctions of policies are:   add a timestamp to every resource  add hard-coded filters to searches to restrict result sets  validate that the user has permission to perform the action   We're going to only allow people to make updates if they are editing themselves. Let's create a policy that checks some\nproperty on the request to see if it matches the resource being updated.  // lib/policies/is-self.policy.js\n\nimport {ForbiddenError} from 'autonym-client-errors';\n\nfunction isSelf (req) {\n  if (req.query.userId !== req.resourceId) {\n    throw new ForbiddenError('You do not have permission to update this resource');\n  }\n}\n\nexport default isSelf;  In this contrived example, our way of telling if the current user is the user being updated, we're simply checking a userId  parameter in the query string. Horribly insecure, but easy to test. Note that we are throwing an instance of ForbiddenError . It is important that your policy throw some subclass from the autonym-client-errors package, such as ForbiddenError . If an internal error occurred (like a rejected database connection or a timeout), just throw it and\nAutonymResponder will return a 500 error and pass it onto your  handleError  method; but if the error just indicates\nsomething the client did wrong, always make sure to throw a subclass of ClientError.  It doesn't matter what the function  returns , unless it is a promise. If it's a promise, then the promise can resolve\nwith anything, or reject and it will be treated just like the throw example.  You may also have noticed the  req.resourceId  property, which is nonstandard on the  req  object in Express. Autonym\naggregates the  req  object with many properties, which are documented in the API reference.  Let's attach this policy to the  findOneAndUpdate  action, which we can do by modifying our schema.  // lib/schemas/person.schema.json\n\n{\n   id :  Person ,\n   type :  object ,\n   policies : {\n     findOneAndUpdate :  isAdmin \n  },\n   properties : {\n     firstName : { type :  string ,  minLength : 1,  maxLength : 20},\n     lastName : { type :  string ,  minLength : 1,  maxLength : 20},\n     employeeId : { type :  string ,  minLength : 1,  maxLength : 10}\n  },\n   required : [ firstName ,  lastName ,  clientId ]\n}  Now if we reattempt a PATCH request on  /people/42 , we should get back a forbidden error. However, if try a request to /people/42?userId=42 , we should get a success (assuming a person with id 42 exists). Obviously this is just a simple\nexample and not a valid means of authentication.  The  policies  object on the schema can have  * ,  create ,  find ,  findOne ,  findOneAndUpdate , and findOneAndDelete  definitions. The  *  applies to  all  CRUD operations and is always evaluated first.  The values in the  policies  object are actually \"asynchronous boolean expressions.\" At their simplest, they're just\nnames of policies. However, you can actually mix and match policies by using the syntax defined in async-boolean-expression-evaluator . This allows you\nto combine policies, like  {\"or\": [\"isAdmin\", \"isSelf\"]}  or {\"and\": [\"isLoggedIn\", {\"or\": [\"isAdmin\", \"canChangePassword\"]}]} .", 
            "title": "Creating a policy"
        }, 
        {
            "location": "/getting-started/#afterword", 
            "text": "Hopefully this tutorial helped you get started with your first Autonym app! There's a lot more to it, and also a lot\nmore work for us to do. Please let us know what you think in the Issues section, and as always, pull requests are\nwelcome!", 
            "title": "Afterword"
        }
    ]
}